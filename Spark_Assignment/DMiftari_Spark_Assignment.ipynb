{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "from collections import Counter\n",
    "from scipy.sparse import coo_matrix, save_npz\n",
    "from datetime import datetime\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PySpark Intro\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "tweets = spark.read.options(samplingRatio=0.01).json('gs://bgse-datawarehousing-random-tweets')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdd magic on the file\n",
    "\n",
    "tweets_hashtags = tweets.rdd\\\n",
    "    .map(lambda r: r.entities)\\\n",
    "    .filter(lambda x: x is not None)\\\n",
    "    .map(lambda r: r.hashtags)\\\n",
    "    .filter(lambda x: len(x) > 1)\\\n",
    "    .map(lambda x: [i[1] for i in x])\\\n",
    "    .collect()\n",
    "    \n",
    "# organize the data \n",
    "\n",
    "perms = map(lambda x: list(it.permutations(x, 2)), tweets_hashtags)\n",
    "\n",
    "combined_list = reduce(lambda a,b : a+b, perms)\n",
    "\n",
    "tweet_pairs = [(x.lower(), y.lower()) for x,y in combined_list]\n",
    "\n",
    "countsold = list(Counter(tweet_pairs).items())\n",
    "\n",
    "counts = [[item[0][0], item[0][1], item[1]] for item in countsold]\n",
    "\n",
    "unique_pairs = (set(tweet_pairs))\n",
    "\n",
    "# create dictionary of unique individual hashtags\n",
    "\n",
    "unique_hashtags1 = [i[0] for i in unique_pairs]\n",
    "unique_hashtags2 = [i[1] for i in unique_pairs]\n",
    "unique_hashtags = (set(unique_hashtags1 + unique_hashtags2))\n",
    "\n",
    "unique_hashtags_index = {item:val for val, item in enumerate(unique_hashtags)}\n",
    "\n",
    "# map each item in pairs to match value in dictionary\n",
    "\n",
    "list1 = [i[0] for i in counts]\n",
    "list2 = [i[1] for i in counts]\n",
    "counts_list = [i[2] for i in counts] \n",
    "\n",
    "# create row and column index\n",
    "\n",
    "row_index = map(lambda x: unique_hashtags_index.get(x), list1)\n",
    "column_index = map(lambda x: unique_hashtags_index.get(x), list2)\n",
    "\n",
    "# Constructing a sparse matrix \n",
    "row  = np.array(row_index)\n",
    "col  = np.array(column_index)\n",
    "data = np.array(counts_list)\n",
    "final_matrix = coo_matrix((data, (row, col)))\n",
    "\n",
    "# save file\n",
    "\n",
    "save_npz(\"final_matrix.npz\", final_matrix, compressed = True)\n",
    "\n",
    "# evaluate the time performance\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
